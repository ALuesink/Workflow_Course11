Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	get_PMIDs
	1

rule get_PMIDs:
    input: Data/Oefen_RNA-Seq-IDs.txt
    output: Data/Oefen_PMIDs.txt
    jobid: 1

    Error in rule get_PMIDs:
        jobid: 1
        output: Data/Oefen_PMIDs.txt

RuleException:
WorkflowError in line 18 of /home/sanne/Documents/AAA-Sanne/git/Workflow_Course11/Snakefile:
URLError: <urlopen error [Errno 2] No such file or directory: '/home/sanne/Documents/AAA-Sanne/git/Workflow_Course11/python Scripts/Get_PMIDs.py'>
  File "/home/sanne/Documents/AAA-Sanne/git/Workflow_Course11/Snakefile", line 18, in __rule_get_PMIDs
  File "/home/sanne/anaconda3/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/sanne/Documents/AAA-Sanne/git/Workflow_Course11/.snakemake/log/2018-06-04T130854.145256.snakemake.log
